{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whitening_robert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKrqXS7DSrMGPZnnfxh+ow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepankar27/ML_Tutorials/blob/master/NLP/Dim_Reduction/Whitening_robert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-evJTrykDUB",
        "outputId": "555e6bcb-48b0-4cdd-e310-cf81c015c520"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.6.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.45)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.0.0-py3-none-any.whl size=126709 sha256=cd211c9a7e7af30c920fda73b8e77c245ef6ab705f1c25f6ae9e9fd4ae660298\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/0f/faafd427f705c4b012274ba60d9a91d75830306811e1355293\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.0.0 sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grdO_tpkk2rj",
        "outputId": "b4cc3a56-400c-4572-f2bb-439d05cc7c9c"
      },
      "source": [
        "!wget https://github.com/autoliuweijie/BERT-whitening-pytorch/archive/refs/heads/main.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-12 02:43:44--  https://github.com/autoliuweijie/BERT-whitening-pytorch/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/autoliuweijie/BERT-whitening-pytorch/zip/refs/heads/main [following]\n",
            "--2021-08-12 02:43:44--  https://codeload.github.com/autoliuweijie/BERT-whitening-pytorch/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [     <=>            ]  24.01M  17.1MB/s    in 1.4s    \n",
            "\n",
            "2021-08-12 02:43:46 (17.1 MB/s) - ‘main.zip’ saved [25178904]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2polTGmiqpr",
        "outputId": "297dfcca-240e-47c2-a6ee-e5162328f86a"
      },
      "source": [
        "!unzip /content/main.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/main.zip\n",
            "f52f7c34c7c1a1b409ff9c0d59d3fa02958ee83a\n",
            "   creating: BERT-whitening-pytorch-main/\n",
            "  inflating: BERT-whitening-pytorch-main/.gitignore  \n",
            "  inflating: BERT-whitening-pytorch-main/LICENSE  \n",
            "  inflating: BERT-whitening-pytorch-main/README.md  \n",
            "  inflating: BERT-whitening-pytorch-main/all_utils.py  \n",
            "   creating: BERT-whitening-pytorch-main/data/\n",
            "  inflating: BERT-whitening-pytorch-main/data/download_datasets.sh  \n",
            "   creating: BERT-whitening-pytorch-main/data/downstream/\n",
            "  inflating: BERT-whitening-pytorch-main/data/downstream/get_transfer_data.bash  \n",
            "  inflating: BERT-whitening-pytorch-main/data/downstream/tokenizer.sed  \n",
            "  inflating: BERT-whitening-pytorch-main/eval_with_whitening(nli).py  \n",
            "  inflating: BERT-whitening-pytorch-main/eval_with_whitening(target).py  \n",
            "  inflating: BERT-whitening-pytorch-main/eval_without_whitening.py  \n",
            "   creating: BERT-whitening-pytorch-main/model/\n",
            "  inflating: BERT-whitening-pytorch-main/model/download_models.sh  \n",
            "  inflating: BERT-whitening-pytorch-main/qqp_search_with_faiss.py  \n",
            "  inflating: BERT-whitening-pytorch-main/run.sh  \n",
            "  inflating: BERT-whitening-pytorch-main/run_example.py  \n",
            "   creating: BERT-whitening-pytorch-main/senteval/\n",
            "  inflating: BERT-whitening-pytorch-main/senteval/__init__.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/binary.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/engine.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/mrpc.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/probing.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/rank.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/sick.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/snli.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/sst.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/sts.py  \n",
            "   creating: BERT-whitening-pytorch-main/senteval/tools/\n",
            " extracting: BERT-whitening-pytorch-main/senteval/tools/__init__.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/tools/classifier.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/tools/ranking.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/tools/relatedness.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/tools/validation.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/trec.py  \n",
            "  inflating: BERT-whitening-pytorch-main/senteval/utils.py  \n",
            "  inflating: BERT-whitening-pytorch-main/train_whiten(nli).py  \n",
            "   creating: BERT-whitening-pytorch-main/whiten/\n",
            "  inflating: BERT-whitening-pytorch-main/whiten/bert-base-nli-mean-tokens-first_last_avg-whiten(NLI).pkl  \n",
            "  inflating: BERT-whitening-pytorch-main/whiten/bert-base-uncased-first_last_avg-whiten(NLI).pkl  \n",
            "  inflating: BERT-whitening-pytorch-main/whiten/bert-large-nli-mean-tokens-first_last_avg-whiten(NLI).pkl  \n",
            "  inflating: BERT-whitening-pytorch-main/whiten/bert-large-uncased-first_last_avg-whiten(NLI).pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOk2g-EPmqoh",
        "outputId": "3d49f0eb-e063-440c-9396-b1828de708ec"
      },
      "source": [
        "!apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 1s (1,613 kB/s)\n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfCgwOMutHWJ",
        "outputId": "31f72b1f-0f23-4e57-913a-2cf8de6261a7"
      },
      "source": [
        "!python /content/BERT-whitening-pytorch-main/eval_with_whitening\\(target\\).py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-12 04:26:39.821049: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-12 04:26:40,947 : roberta-base-nli-stsb-mean-tokens-whiten-256(first_last_avg) configs: {'encoder': '/content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens', 'pooling': 'first_last_avg', 'n_components': 256}\n",
            "2021-08-12 04:26:45,203 : Building /content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens tokenizer and model successfuly.\n",
            "2021-08-12 04:26:45,204 : ***** Transfer task : STS12 *****\n",
            "\n",
            "\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
            "2021-08-12 04:27:30,269 : Get whiten kernel and bias from 6216 samples.\n",
            "2021-08-12 04:27:41,625 : MSRpar : pearson = 0.8689, spearman = 0.8435\n",
            "2021-08-12 04:27:52,772 : MSRvid : pearson = 0.9246, spearman = 0.9131\n",
            "2021-08-12 04:27:59,389 : SMTeuroparl : pearson = 0.5403, spearman = 0.5957\n",
            "2021-08-12 04:28:09,724 : surprise.OnWN : pearson = 0.7386, spearman = 0.7111\n",
            "2021-08-12 04:28:15,285 : surprise.SMTnews : pearson = 0.6310, spearman = 0.5499\n",
            "2021-08-12 04:28:15,285 : ALL (weighted average) : Pearson = 0.7718,             Spearman = 0.7541\n",
            "2021-08-12 04:28:15,285 : ALL (average) : Pearson = 0.7407,             Spearman = 0.7227\n",
            "\n",
            "2021-08-12 04:28:15,285 : ***** Transfer task : STS13 (-SMT) *****\n",
            "\n",
            "\n",
            "2021-08-12 04:28:36,231 : Get whiten kernel and bias from 3000 samples.\n",
            "2021-08-12 04:28:39,085 : FNWN : pearson = 0.5591, spearman = 0.6069\n",
            "2021-08-12 04:28:50,204 : headlines : pearson = 0.9306, spearman = 0.9278\n",
            "2021-08-12 04:28:58,499 : OnWN : pearson = 0.8690, spearman = 0.8385\n",
            "2021-08-12 04:28:58,499 : ALL (weighted average) : Pearson = 0.8607,             Spearman = 0.8540\n",
            "2021-08-12 04:28:58,499 : ALL (average) : Pearson = 0.7862,             Spearman = 0.7911\n",
            "\n",
            "2021-08-12 04:28:58,499 : ***** Transfer task : STS14 *****\n",
            "\n",
            "\n",
            "2021-08-12 04:29:50,774 : Get whiten kernel and bias from 7500 samples.\n",
            "2021-08-12 04:29:57,468 : deft-forum : pearson = 0.9077, spearman = 0.9047\n",
            "2021-08-12 04:30:01,990 : deft-news : pearson = 0.9389, spearman = 0.9172\n",
            "2021-08-12 04:30:12,664 : headlines : pearson = 0.9214, spearman = 0.9181\n",
            "2021-08-12 04:30:23,077 : images : pearson = 0.9214, spearman = 0.9058\n",
            "2021-08-12 04:30:33,464 : OnWN : pearson = 0.8922, spearman = 0.8691\n",
            "2021-08-12 04:30:43,824 : tweet-news : pearson = 0.7854, spearman = 0.7534\n",
            "2021-08-12 04:30:43,824 : ALL (weighted average) : Pearson = 0.8881,             Spearman = 0.8712\n",
            "2021-08-12 04:30:43,824 : ALL (average) : Pearson = 0.8945,             Spearman = 0.8780\n",
            "\n",
            "2021-08-12 04:30:43,825 : ***** Transfer task : STS15 *****\n",
            "\n",
            "\n",
            "2021-08-12 04:31:26,682 : Get whiten kernel and bias from 6000 samples.\n",
            "2021-08-12 04:31:31,921 : answers-forums : pearson = 0.7655, spearman = 0.7683\n",
            "2021-08-12 04:31:42,268 : answers-students : pearson = 0.7645, spearman = 0.7863\n",
            "2021-08-12 04:31:47,578 : belief : pearson = 0.8360, spearman = 0.8333\n",
            "2021-08-12 04:31:58,434 : headlines : pearson = 0.9408, spearman = 0.9402\n",
            "2021-08-12 04:32:09,575 : images : pearson = 0.9263, spearman = 0.9287\n",
            "2021-08-12 04:32:09,575 : ALL (weighted average) : Pearson = 0.8581,             Spearman = 0.8640\n",
            "2021-08-12 04:32:09,576 : ALL (average) : Pearson = 0.8466,             Spearman = 0.8514\n",
            "\n",
            "2021-08-12 04:32:09,576 : ***** Transfer task : STS16 *****\n",
            "\n",
            "\n",
            "2021-08-12 04:32:26,615 : Get whiten kernel and bias from 2372 samples.\n",
            "2021-08-12 04:32:30,178 : answer-answer : pearson = 0.7897, spearman = 0.7843\n",
            "2021-08-12 04:32:33,656 : headlines : pearson = 0.9435, spearman = 0.9418\n",
            "2021-08-12 04:32:36,855 : plagiarism : pearson = 0.8103, spearman = 0.8303\n",
            "2021-08-12 04:32:40,251 : postediting : pearson = 0.8874, spearman = 0.8954\n",
            "2021-08-12 04:32:43,149 : question-question : pearson = 0.7710, spearman = 0.7692\n",
            "2021-08-12 04:32:43,149 : ALL (weighted average) : Pearson = 0.8428,             Spearman = 0.8465\n",
            "2021-08-12 04:32:43,150 : ALL (average) : Pearson = 0.8404,             Spearman = 0.8442\n",
            "\n",
            "2021-08-12 04:32:43,150 : ***** Transfer task : SICK-Relatedness*****\n",
            "\n",
            "\n",
            "2021-08-12 04:35:03,087 : Get whiten kernel and bias from 19854 samples.\n",
            "2021-08-12 04:35:03,091 : Computing embedding for test\n",
            "2021-08-12 04:36:12,473 : Computed test embeddings\n",
            "2021-08-12 04:36:12,876 : Test : Pearson 0.7430294666401985 Spearman 0.7375840529549184 MSE 9.978560234932612\n",
            "\n",
            "2021-08-12 04:36:12,879 : \n",
            "\n",
            "***** Transfer task : STSBenchmark*****\n",
            "\n",
            "\n",
            "2021-08-12 04:38:13,117 : Get whiten kernel and bias from 17256 samples.\n",
            "2021-08-12 04:38:13,121 : Computing embedding for test\n",
            "2021-08-12 04:38:33,223 : Computed test embeddings\n",
            "2021-08-12 04:38:33,382 : Test : Pearson 0.851044694573365 Spearman 0.8478299213595558 MSE 6.109949182835647\n",
            "\n",
            "2021-08-12 04:38:33,383 : roberta-base-nli-stsb-mean-tokens-whiten-256(first_last_avg) results:\n",
            "+----------------------+--------------------+\n",
            "|         Task         |      Spearman      |\n",
            "+----------------------+--------------------+\n",
            "|        STS12         | 0.7540542151933405 |\n",
            "|        STS13         | 0.8539614963904958 |\n",
            "|        STS14         | 0.8712166252487574 |\n",
            "|        STS15         | 0.8639951285144317 |\n",
            "|        STS16         | 0.8464893070848573 |\n",
            "| SICKRelatednessCosin | 0.7375840529549184 |\n",
            "|  STSBenchmarkCosin   | 0.8478299213595558 |\n",
            "+----------------------+--------------------+\n",
            "2021-08-12 04:38:33,406 : roberta-base-nli-stsb-mean-tokens-whiten-256(last_avg) configs: {'encoder': '/content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens', 'pooling': 'last_avg', 'n_components': 256}\n",
            "2021-08-12 04:38:34,805 : Building /content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens tokenizer and model successfuly.\n",
            "2021-08-12 04:38:34,805 : ***** Transfer task : STS12 *****\n",
            "\n",
            "\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
            "2021-08-12 04:39:19,187 : Get whiten kernel and bias from 6216 samples.\n",
            "2021-08-12 04:39:29,696 : MSRpar : pearson = 0.8722, spearman = 0.8477\n",
            "2021-08-12 04:39:40,469 : MSRvid : pearson = 0.9275, spearman = 0.9161\n",
            "2021-08-12 04:39:47,324 : SMTeuroparl : pearson = 0.5313, spearman = 0.5849\n",
            "2021-08-12 04:39:58,499 : surprise.OnWN : pearson = 0.7282, spearman = 0.7008\n",
            "2021-08-12 04:40:04,164 : surprise.SMTnews : pearson = 0.5998, spearman = 0.5225\n",
            "2021-08-12 04:40:04,164 : ALL (weighted average) : Pearson = 0.7655,             Spearman = 0.7482\n",
            "2021-08-12 04:40:04,164 : ALL (average) : Pearson = 0.7318,             Spearman = 0.7144\n",
            "\n",
            "2021-08-12 04:40:04,164 : ***** Transfer task : STS13 (-SMT) *****\n",
            "\n",
            "\n",
            "2021-08-12 04:40:25,049 : Get whiten kernel and bias from 3000 samples.\n",
            "2021-08-12 04:40:27,732 : FNWN : pearson = 0.5256, spearman = 0.5747\n",
            "2021-08-12 04:40:38,118 : headlines : pearson = 0.9375, spearman = 0.9346\n",
            "2021-08-12 04:40:46,277 : OnWN : pearson = 0.8665, spearman = 0.8381\n",
            "2021-08-12 04:40:46,277 : ALL (weighted average) : Pearson = 0.8591,             Spearman = 0.8532\n",
            "2021-08-12 04:40:46,277 : ALL (average) : Pearson = 0.7766,             Spearman = 0.7825\n",
            "\n",
            "2021-08-12 04:40:46,277 : ***** Transfer task : STS14 *****\n",
            "\n",
            "\n",
            "2021-08-12 04:41:39,420 : Get whiten kernel and bias from 7500 samples.\n",
            "2021-08-12 04:41:45,664 : deft-forum : pearson = 0.9181, spearman = 0.9137\n",
            "2021-08-12 04:41:50,162 : deft-news : pearson = 0.9402, spearman = 0.9232\n",
            "2021-08-12 04:42:01,368 : headlines : pearson = 0.9311, spearman = 0.9286\n",
            "2021-08-12 04:42:12,560 : images : pearson = 0.9232, spearman = 0.9079\n",
            "2021-08-12 04:42:23,101 : OnWN : pearson = 0.8904, spearman = 0.8631\n",
            "2021-08-12 04:42:33,690 : tweet-news : pearson = 0.7777, spearman = 0.7500\n",
            "2021-08-12 04:42:33,691 : ALL (weighted average) : Pearson = 0.8899,             Spearman = 0.8734\n",
            "2021-08-12 04:42:33,691 : ALL (average) : Pearson = 0.8968,             Spearman = 0.8811\n",
            "\n",
            "2021-08-12 04:42:33,691 : ***** Transfer task : STS15 *****\n",
            "\n",
            "\n",
            "2021-08-12 04:43:17,143 : Get whiten kernel and bias from 6000 samples.\n",
            "2021-08-12 04:43:22,814 : answers-forums : pearson = 0.7579, spearman = 0.7606\n",
            "2021-08-12 04:43:33,984 : answers-students : pearson = 0.7508, spearman = 0.7730\n",
            "2021-08-12 04:43:39,769 : belief : pearson = 0.8351, spearman = 0.8351\n",
            "2021-08-12 04:43:51,061 : headlines : pearson = 0.9467, spearman = 0.9457\n",
            "2021-08-12 04:44:01,727 : images : pearson = 0.9289, spearman = 0.9307\n",
            "2021-08-12 04:44:01,728 : ALL (weighted average) : Pearson = 0.8557,             Spearman = 0.8618\n",
            "2021-08-12 04:44:01,728 : ALL (average) : Pearson = 0.8439,             Spearman = 0.8490\n",
            "\n",
            "2021-08-12 04:44:01,728 : ***** Transfer task : STS16 *****\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQuVlqzTutfi",
        "outputId": "32a0703d-a26a-4b4c-a2ea-30ae8833c64f"
      },
      "source": [
        "!python /content/BERT-whitening-pytorch-main/eval_without_whitening.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-11 17:47:48.890200: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-11 17:47:50,038 : roberta-base-nli-stsb-mean-tokens-first_last_avg configs: {'encoder': '/content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens', 'pooling': 'first_last_avg'}\n",
            "2021-08-11 17:47:54,589 : Building /content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens tokenizer and model successfuly.\n",
            "2021-08-11 17:47:54,590 : ***** Transfer task : STS12 *****\n",
            "\n",
            "\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
            "2021-08-11 17:48:05,658 : MSRpar : pearson = 0.8836, spearman = 0.8651\n",
            "2021-08-11 17:48:16,451 : MSRvid : pearson = 0.9526, spearman = 0.9509\n",
            "2021-08-11 17:48:23,047 : SMTeuroparl : pearson = 0.5313, spearman = 0.5642\n",
            "2021-08-11 17:48:33,380 : surprise.OnWN : pearson = 0.7257, spearman = 0.7038\n",
            "2021-08-11 17:48:38,831 : surprise.SMTnews : pearson = 0.6305, spearman = 0.5608\n",
            "2021-08-11 17:48:38,832 : ALL (weighted average) : Pearson = 0.7776,             Spearman = 0.7634\n",
            "2021-08-11 17:48:38,832 : ALL (average) : Pearson = 0.7447,             Spearman = 0.7290\n",
            "\n",
            "2021-08-11 17:48:38,832 : ***** Transfer task : STS13 (-SMT) *****\n",
            "\n",
            "\n",
            "2021-08-11 17:48:41,563 : FNWN : pearson = 0.5567, spearman = 0.5596\n",
            "2021-08-11 17:48:51,646 : headlines : pearson = 0.9475, spearman = 0.9470\n",
            "2021-08-11 17:48:59,160 : OnWN : pearson = 0.8439, spearman = 0.8265\n",
            "2021-08-11 17:48:59,160 : ALL (weighted average) : Pearson = 0.8595,             Spearman = 0.8531\n",
            "2021-08-11 17:48:59,160 : ALL (average) : Pearson = 0.7827,             Spearman = 0.7777\n",
            "\n",
            "2021-08-11 17:48:59,160 : ***** Transfer task : STS14 *****\n",
            "\n",
            "\n",
            "2021-08-11 17:49:05,237 : deft-forum : pearson = 0.9459, spearman = 0.9472\n",
            "2021-08-11 17:49:09,589 : deft-news : pearson = 0.9600, spearman = 0.9465\n",
            "2021-08-11 17:49:20,413 : headlines : pearson = 0.9379, spearman = 0.9401\n",
            "2021-08-11 17:49:31,154 : images : pearson = 0.9413, spearman = 0.9178\n",
            "2021-08-11 17:49:41,281 : OnWN : pearson = 0.8698, spearman = 0.8557\n",
            "2021-08-11 17:49:51,537 : tweet-news : pearson = 0.8030, spearman = 0.7596\n",
            "2021-08-11 17:49:51,537 : ALL (weighted average) : Pearson = 0.9007,             Spearman = 0.8840\n",
            "2021-08-11 17:49:51,537 : ALL (average) : Pearson = 0.9097,             Spearman = 0.8945\n",
            "\n",
            "2021-08-11 17:49:51,540 : ***** Transfer task : STS15 *****\n",
            "\n",
            "\n",
            "2021-08-11 17:49:56,725 : answers-forums : pearson = 0.7229, spearman = 0.7193\n",
            "2021-08-11 17:50:06,762 : answers-students : pearson = 0.7908, spearman = 0.8023\n",
            "2021-08-11 17:50:11,882 : belief : pearson = 0.8052, spearman = 0.8000\n",
            "2021-08-11 17:50:22,640 : headlines : pearson = 0.9525, spearman = 0.9566\n",
            "2021-08-11 17:50:33,436 : images : pearson = 0.9565, spearman = 0.9615\n",
            "2021-08-11 17:50:33,436 : ALL (weighted average) : Pearson = 0.8659,             Spearman = 0.8700\n",
            "2021-08-11 17:50:33,436 : ALL (average) : Pearson = 0.8456,             Spearman = 0.8479\n",
            "\n",
            "2021-08-11 17:50:33,439 : ***** Transfer task : STS16 *****\n",
            "\n",
            "\n",
            "2021-08-11 17:50:37,190 : answer-answer : pearson = 0.7671, spearman = 0.7611\n",
            "2021-08-11 17:50:40,542 : headlines : pearson = 0.9410, spearman = 0.9444\n",
            "2021-08-11 17:50:43,652 : plagiarism : pearson = 0.8380, spearman = 0.8562\n",
            "2021-08-11 17:50:47,007 : postediting : pearson = 0.8678, spearman = 0.8893\n",
            "2021-08-11 17:50:49,825 : question-question : pearson = 0.7331, spearman = 0.7279\n",
            "2021-08-11 17:50:49,825 : ALL (weighted average) : Pearson = 0.8321,             Spearman = 0.8386\n",
            "2021-08-11 17:50:49,825 : ALL (average) : Pearson = 0.8294,             Spearman = 0.8358\n",
            "\n",
            "2021-08-11 17:50:49,830 : ***** Transfer task : SICK-Relatedness*****\n",
            "\n",
            "\n",
            "2021-08-11 17:50:49,967 : Computing embedding for test\n",
            "2021-08-11 17:51:57,262 : Computed test embeddings\n",
            "2021-08-11 17:51:57,667 : Test : Pearson 0.8161876934432255 Spearman 0.7745165130976116 MSE 8.64691553504995\n",
            "\n",
            "2021-08-11 17:51:57,671 : \n",
            "\n",
            "***** Transfer task : STSBenchmark*****\n",
            "\n",
            "\n",
            "2021-08-11 17:51:57,709 : Computing embedding for test\n",
            "2021-08-11 17:52:16,224 : Computed test embeddings\n",
            "2021-08-11 17:52:16,327 : Test : Pearson 0.8460060727562397 Spearman 0.8535628926613655 MSE 5.533029019255591\n",
            "\n",
            "2021-08-11 17:52:16,330 : roberta-base-nli-stsb-mean-tokens-first_last_avg results:\n",
            "+----------------------+--------------------+\n",
            "|         Task         |      Spearman      |\n",
            "+----------------------+--------------------+\n",
            "|        STS12         | 0.7633774156044587 |\n",
            "|        STS13         | 0.8531324481349571 |\n",
            "|        STS14         | 0.8840128699555457 |\n",
            "|        STS15         | 0.8699963831141986 |\n",
            "|        STS16         | 0.8385591080433688 |\n",
            "| SICKRelatednessCosin | 0.7745165130976116 |\n",
            "|  STSBenchmarkCosin   | 0.8535628926613655 |\n",
            "+----------------------+--------------------+\n",
            "2021-08-11 17:52:16,350 : roberta-base-nli-stsb-mean-tokens-cls configs: {'encoder': '/content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens', 'pooling': 'cls'}\n",
            "2021-08-11 17:52:17,681 : Building /content/BERT-whitening-pytorch-main/model/roberta-base-nli-stsb-mean-tokens tokenizer and model successfuly.\n",
            "2021-08-11 17:52:17,681 : ***** Transfer task : STS12 *****\n",
            "\n",
            "\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
            "/content/BERT-whitening-pytorch-main/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
            "2021-08-11 17:52:28,501 : MSRpar : pearson = 0.8647, spearman = 0.8488\n",
            "2021-08-11 17:52:39,308 : MSRvid : pearson = 0.9538, spearman = 0.9535\n",
            "2021-08-11 17:52:45,945 : SMTeuroparl : pearson = 0.5174, spearman = 0.5464\n",
            "2021-08-11 17:52:56,430 : surprise.OnWN : pearson = 0.7024, spearman = 0.6826\n",
            "2021-08-11 17:53:02,144 : surprise.SMTnews : pearson = 0.6128, spearman = 0.5337\n",
            "2021-08-11 17:53:02,144 : ALL (weighted average) : Pearson = 0.7634,             Spearman = 0.7488\n",
            "2021-08-11 17:53:02,144 : ALL (average) : Pearson = 0.7302,             Spearman = 0.7130\n",
            "\n",
            "2021-08-11 17:53:02,144 : ***** Transfer task : STS13 (-SMT) *****\n",
            "\n",
            "\n",
            "2021-08-11 17:53:04,933 : FNWN : pearson = 0.5578, spearman = 0.5600\n",
            "2021-08-11 17:53:15,688 : headlines : pearson = 0.9462, spearman = 0.9441\n",
            "2021-08-11 17:53:23,661 : OnWN : pearson = 0.8397, spearman = 0.8225\n",
            "2021-08-11 17:53:23,661 : ALL (weighted average) : Pearson = 0.8574,             Spearman = 0.8502\n",
            "2021-08-11 17:53:23,662 : ALL (average) : Pearson = 0.7812,             Spearman = 0.7755\n",
            "\n",
            "2021-08-11 17:53:23,662 : ***** Transfer task : STS14 *****\n",
            "\n",
            "\n",
            "2021-08-11 17:53:29,738 : deft-forum : pearson = 0.9486, spearman = 0.9490\n",
            "2021-08-11 17:53:33,896 : deft-news : pearson = 0.9536, spearman = 0.9377\n",
            "2021-08-11 17:53:44,035 : headlines : pearson = 0.9374, spearman = 0.9401\n",
            "2021-08-11 17:53:54,080 : images : pearson = 0.9411, spearman = 0.9177\n",
            "2021-08-11 17:54:04,264 : OnWN : pearson = 0.8640, spearman = 0.8468\n",
            "2021-08-11 17:54:15,173 : tweet-news : pearson = 0.7840, spearman = 0.7352\n",
            "2021-08-11 17:54:15,173 : ALL (weighted average) : Pearson = 0.8954,             Spearman = 0.8768\n",
            "2021-08-11 17:54:15,173 : ALL (average) : Pearson = 0.9048,             Spearman = 0.8877\n",
            "\n",
            "2021-08-11 17:54:15,174 : ***** Transfer task : STS15 *****\n",
            "\n",
            "\n",
            "2021-08-11 17:54:20,708 : answers-forums : pearson = 0.7266, spearman = 0.7204\n",
            "2021-08-11 17:54:31,230 : answers-students : pearson = 0.7830, spearman = 0.7937\n",
            "2021-08-11 17:54:36,366 : belief : pearson = 0.7791, spearman = 0.7682\n",
            "2021-08-11 17:54:46,502 : headlines : pearson = 0.9512, spearman = 0.9531\n",
            "2021-08-11 17:54:56,649 : images : pearson = 0.9596, spearman = 0.9623\n",
            "2021-08-11 17:54:56,649 : ALL (weighted average) : Pearson = 0.8617,             Spearman = 0.8634\n",
            "2021-08-11 17:54:56,649 : ALL (average) : Pearson = 0.8399,             Spearman = 0.8396\n",
            "\n",
            "2021-08-11 17:54:56,649 : ***** Transfer task : STS16 *****\n",
            "\n",
            "\n",
            "2021-08-11 17:55:00,294 : answer-answer : pearson = 0.7448, spearman = 0.7407\n",
            "2021-08-11 17:55:03,639 : headlines : pearson = 0.9343, spearman = 0.9361\n",
            "2021-08-11 17:55:06,773 : plagiarism : pearson = 0.8425, spearman = 0.8546\n",
            "2021-08-11 17:55:10,237 : postediting : pearson = 0.8529, spearman = 0.8716\n",
            "2021-08-11 17:55:13,258 : question-question : pearson = 0.7222, spearman = 0.7210\n",
            "2021-08-11 17:55:13,258 : ALL (weighted average) : Pearson = 0.8218,             Spearman = 0.8272\n",
            "2021-08-11 17:55:13,258 : ALL (average) : Pearson = 0.8193,             Spearman = 0.8248\n",
            "\n",
            "2021-08-11 17:55:13,258 : ***** Transfer task : SICK-Relatedness*****\n",
            "\n",
            "\n",
            "2021-08-11 17:55:13,288 : Computing embedding for test\n",
            "2021-08-11 17:56:20,641 : Computed test embeddings\n",
            "2021-08-11 17:56:21,056 : Test : Pearson 0.8049033390939073 Spearman 0.7678831750541435 MSE 9.046433153624925\n",
            "\n",
            "2021-08-11 17:56:21,060 : \n",
            "\n",
            "***** Transfer task : STSBenchmark*****\n",
            "\n",
            "\n",
            "2021-08-11 17:56:21,099 : Computing embedding for test\n",
            "2021-08-11 17:56:40,632 : Computed test embeddings\n",
            "2021-08-11 17:56:40,740 : Test : Pearson 0.8335460769601358 Spearman 0.8441918574548812 MSE 5.712647516295079\n",
            "\n",
            "2021-08-11 17:56:40,742 : roberta-base-nli-stsb-mean-tokens-cls results:\n",
            "+----------------------+--------------------+\n",
            "|         Task         |      Spearman      |\n",
            "+----------------------+--------------------+\n",
            "|        STS12         | 0.7488463476027744 |\n",
            "|        STS13         |  0.85021468769516  |\n",
            "|        STS14         | 0.876834912737469  |\n",
            "|        STS15         | 0.8633684721549444 |\n",
            "|        STS16         | 0.8272490615963751 |\n",
            "| SICKRelatednessCosin | 0.7678831750541435 |\n",
            "|  STSBenchmarkCosin   | 0.8441918574548812 |\n",
            "+----------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tf39dXgMn_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}